#!/usr/bin/env python
#
# (c) Copyright 2008 Cloudera, Inc.
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#

"""
  Installation tool for Cloudera Hadoop Distribution
  main entry point

  Usage: install [options]
  Type "install --help" for full usage instructions
"""

import logging
import os
import shutil
import sys
import time

import com.cloudera.distribution.arch as arch
from   com.cloudera.distribution.constants import *
import com.cloudera.distribution.env as env
from   com.cloudera.distribution.installerror import InstallError
import com.cloudera.distribution.installproperties as installproperties
import com.cloudera.distribution.manifest as manifest
import com.cloudera.distribution.postinstall as postinstall
import com.cloudera.distribution.remotemgr as remotemgr
import com.cloudera.distribution.roles as roles
import com.cloudera.distribution.serializer as serializer
import com.cloudera.distribution.toolinstall as toolinstall
import com.cloudera.tools.shell as shell
import com.cloudera.util.output as output

# do this before doing anything else.
output.initLogging()

# use all args except program name
argv = sys.argv[1:]

# set up configuration, init stdout/stderr
properties = installproperties.InstallProperties()
output.attachOutputArgParser(properties)

installproperties.loadAllProperties(properties, argv)

# if the user has not selected a log file name, and a log level, force
# a log file in here; also, set the default log level to verbose.
setLogName = properties.getProperty(output.LOG_FILENAME_PROP)
if setLogName == None:
  properties.setProperty(output.LOG_FILENAME_PROP, DEFAULT_LOG_FILENAME)

setLogVerbosity = properties.getProperty(output.LOG_VERBOSITY_PROP)
if setLogVerbosity == None:
  properties.setProperty(output.LOG_VERBOSITY_PROP, DEFAULT_LOG_VERBOSITY)

# CH-120: If we don't have a tty on stdin, then enforce noninteractive mode.
if not sys.stdin.isatty():
  logging.info("Could not find a tty on stdin; forcing unattended installation.")
  properties.setProperty(UNATTEND_INSTALL_KEY, INSTALL_UNATTENDED_VAL)

# record the directory where the user started, for use with relative paths
# to hadoop-site.xml, slaves, etc.
basedir = os.path.abspath(os.getcwd())
properties.setProperty(BASE_DIR_KEY, basedir)

# set up the console. Also starts logging to the specified file.
output.setupConsole(properties)

# if we are here, then properties and argv parsing succeeded.

# record some information for the debug log
logging.debug("*** STARTUP_MSG: installer started: " + time.asctime())
try:
  whoamiLines = shell.shLines("whoami")
  for line in whoamiLines:
    logging.debug("whoami: " + line)
except shell.CommandError:
  pass # This was for debugging only; ignore.

try:
  unameLines = shell.shLines("uname -a")
  for line in unameLines:
    logging.debug("uname -a: " + line)
except shell.CommandError:
  pass # This was for debugging only; ignore.

properties.printTable(logging.DEBUG)

# Where are we? Switch into installer's base dir
binName = sys.argv[0]
binDir = properties.getProperty(INSTALL_BINDIR_KEY, os.path.dirname(binName))
os.chdir(binDir)

logging.debug("installation base dir: "+ basedir)
logging.debug("installer bin dir: " + binDir)

# determine what architecture / platform we're running on.
archDetector = arch.getArchDetector()
archDetector.scan()
if archDetector.getPlatform() == arch.PLATFORM_UNKNOWN:
  output.printlnInfo("Warning: Could not determine linux platform")
  output.printlnInfo("This hampers my ability to determine if you "
      + "have the correct prerequisite")
  output.printlnInfo("packages installed.")

if archDetector.getArch() == arch.ARCH_UNKNOWN:
  # if we can't figure out the arch, then we disable allowing native
  # compression, because we don't want to enable in-Java compression by default
  # by mistake.
  output.printlnInfo("Warning: Could not determine system architecture")
  output.printlnInfo("This hampers my ability to install the correct libraries")
  output.printlnInfo("Disabling native compression libraries in MapReduce")
  properties.setProperty(ALLOW_NATIVE_COMPRESSION_KEY, False)

globalPrereqInstaller = None
action_script = None

try:
  # Determine the roles to install for
  output.printlnDebug("Gathering roles...")
  role_list = roles.get_roles_from_properties(properties)
  output.printlnDebug("Got roles from user: " + str(role_list))

  # Assemble the installation plan from the roles.
  tools_list = roles.get_tools_for_roles(role_list)
  installPlan = manifest.createInstallPlan(tools_list, properties)
  installPlan.verify_dependencies()
  globalPrereqInstaller = toolinstall.getToolByName("GlobalPrereq")

  # Detect any prereqs that we cannot install:
  output.printlnInfo("Checking prerequisites for installation...")
  for tool in installPlan.getInstallItems():
    output.printlnVerbose("Running precheck for item: " + tool.getName())
    tool.precheck()

  output.printlnInfo("All necessary prerequisites were found.")

  output.printlnInfo("""
To set up Hadoop, we need to ask you a few basic questions about your
cluster. When possible, acceptable defaults are provided to you, which you
can select by pressing [enter].
""")

  for tool in installPlan.getInstallItems():
    output.printlnVerbose("Running configure for item: " + tool.getName())
    tool.configure()

  # Any user input should have occurred above this line. From this point
  # forward, we only bail out because an underlying installation item
  # chokes -- this is out of the user's hands by here.

  # execute installation plan
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Installing " + tool.getName())
    tool.install()

  # If we're the master, perform automated deployment to additional machines
  if globalPrereqInstaller.has_role("deployment_master"):
    output.printlnInfo("Deploying distribution to remote hosts.")
    output.printlnInfo("(This may take a few minutes)")
    remote_failed_hosts = remotemgr.deployRemotes(properties)
  else:
    remote_failed_hosts = []

  # any steps to be performed per-tool after the whole system is together
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Performing postinstall for " + tool.getName())
    tool.postInstall()

  if postinstall.has_actions():
    # Write out the postinstall script and move it to its destination.
    action_script_src = postinstall.write_action_script()
    action_script = os.path.join(globalPrereqInstaller.getInstallPrefix(), "postinstall")
    shutil.move(action_script_src, action_script)
    try:
      shell.sh("chmod u+x " + action_script)
    except shell.CommandError:
      raise InstallError("Error writing postinstall action script")

    if globalPrereqInstaller.mayStartDaemons():
      # We're allowed to directly use Hadoop services in this installation if we'd
      # like. Execute the post-install script now
      logging.info("""Setting up your distributed filesystem and starting services...
(This may take a few minutes)
""")
      try:
        postinstall.execute_actions()
        # if the actions ran successfully, just delete the script.
        logging.debug("Removing postinstall script after success: " + action_script)
        os.unlink(action_script)
      except InstallError, ie:
        # If not, display a warning msg but continue the installer.
        logging.error("""Some operations need to be performed before your HDFS instance use ready
for use. These operations have been written to a script, at:
  %(installscript)s
I tried running the script for you, but it failed part-way through:
  %(err)s
You need to correct the error, and then re-run it. You can delete the script
when it has run successfully.

""" % { "installscript" : action_script,
        "err"           : str(ie) })


  # Perform any verification steps that this all installed OK
  for tool in installPlan.getInstallItems():
    output.printlnInfo("Verifying installation of " + tool.getName())
    tool.verify()

except InstallError, ie:
  output.printlnError("An error occurred during the installation process:")
  output.printlnError(str(ie))
  output.printlnError("Installation has been aborted")
  sys.exit(1)


# Calculate and display a large summary banner that describes the state of the install.
remote_deploy_failed = len(remote_failed_hosts) > 0
post_install_needed = action_script != None and os.path.exists(action_script)

if not post_install_needed:
  if not remote_deploy_failed:
    summary = """
The Cloudera Hadoop Distribution installation process is complete!
"""
  else:
    summary = """
The Cloudera Hadoop Distribution install process has completed
locally. Errors were encountered when deploying to remote hosts.
"""

if post_install_needed:
  summary = """
The Cloudera Hadoop Distribution has been installed locally, but you
must run a postinstall script before your system is ready for use.
"""
  if remote_deploy_failed:
    summary += "Also, errors were encountered when deploying to remote hosts.\n"

logging.info("""

***********************************************************************
%(summary)s
***********************************************************************

""" % { "summary" : summary })


# Now print some slightly-more technical information.

globalPrereqName = None
if globalPrereqInstaller != None:
  output.printlnInfo("Distribution installed to %(installdir)s." % \
      { "installdir" : globalPrereqInstaller.getInstallPrefix() })
  output.printlnInfo("Distribution config files are in %(confdir)s." % \
      { "confdir" : globalPrereqInstaller.getConfigDir() } )
  globalPrereqName = globalPrereqInstaller.getName()

output.printlnInfo("")

output.printlnVerbose("Installed components:")
for tool in installPlan.getInstallItems():
  if tool.getName() != globalPrereqName:
    output.printlnVerbose("  " + tool.getName())

hadoopInstaller = toolinstall.getToolByName("Hadoop")
if hadoopInstaller != None and \
    (hadoopInstaller.has_role("namenode") or hadoopInstaller.has_role("jobtracker")):
  hadoopStartCmd = os.path.join(hadoopInstaller.getHadoopBinDir(), \
      "start-all.sh")
  hadoopStopCmd = os.path.join(hadoopInstaller.getHadoopBinDir(), \
      "stop-all.sh")
  output.printlnInfo("You can start Hadoop by running:\n$ %(hadoopStart)s" % \
      { "hadoopStart" : hadoopStartCmd })
  if hadoopInstaller.isHadoopVerified():
    output.printlnInfo("(Note: Hadoop has already been started for you.)")
  output.printlnInfo("You can stop Hadoop by running:\n$ %(hadoopStop)s" % \
      { "hadoopStop" : hadoopStopCmd })
  output.printlnInfo("")


# If there were warnings or more user-run steps, list the follow-up
# actions that must be taken.

if len(remote_failed_hosts) > 0:
  output.printlnInfo("There were errors deploying the distribution to the " \
    + "following remote hosts:")
  for host in remote_failed_hosts:
    output.printlnInfo("  " + host)
  output.printlnInfo("You may need to manually install on these hosts.")


# any tool-specific user-run steps/warnings are emitted here:
for tool in installPlan.getInstallItems():
  tool.printFinalInstructions()

# if we have a postinstall script present, tell the user to run it.
if post_install_needed:
  logging.info("""
Before your cluster is ready for use, a postinstall script must be run once.
The command to run this script is:
  %(script)s
This should be run as your current username (%(user)s). This should run
after any HDFS format commands.
""" % { "script" : os.path.abspath(action_script),
        "user"   : globalPrereqInstaller.getCurrUser() })


# echo out information about the user's environment.
env.writeEnvironmentScript()

# TODO(aaron) - Remove this block.
# This is only a test of the serializer/deserializer code.
#serializer.preserve_state(SERIALIZATION_FILENAME)
#tools=serializer.restore_state(SERIALIZATION_FILENAME, roles.get_role_names(), properties)
#for tool in tools:
#  print "got tool back: " + tool.getName()

logging.debug("*** installer exit")

sys.exit(0)

