<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!--
     Autogenerated by Cloudera Hadoop Installer on
     Mon Dec  8 08:30:09 2008

     You *may* edit this file. Put site-specific property overrides below.
-->
<configuration>
<property>
  <name>dfs.block.size</name>
  <value>134217728</value>
  <final>true</final>
</property>
<property>
  <name>dfs.data.dir</name>
  <value>/tmp/data</value>
  <final>true</final>
</property>
<property>
  <name>dfs.datanode.du.reserved</name>
  <value>1073741824</value>
  <final>true</final>
</property>
<property>
  <name>dfs.datanode.handler.count</name>
  <value>3</value>
  <final>true</final>
</property>
<property>
  <name>dfs.hosts</name>
  <value>/tmp/master/apps/hadoop-0.18.2/conf/dfs.hosts</value>
  <final>true</final>
</property>
<property>
  <name>dfs.hosts.exclude</name>
  <value>/tmp/master/apps/hadoop-0.18.2/conf/dfs.hosts.exclude</value>
  <final>true</final>
</property>
<property>
  <name>dfs.name.dir</name>
  <value>/tmp/name</value>
  <final>true</final>
</property>
<property>
  <name>dfs.namenode.handler.count</name>
  <value>5</value>
  <final>true</final>
</property>
<property>
  <name>dfs.permissions</name>
  <value>True</value>
  <final>true</final>
</property>
<property>
  <name>dfs.replication</name>
  <value>3</value>
</property>
<property>
  <name>fs.checkpoint.dir</name>
  <value>/home/hadoop/hdfs/secondary</value>
  <final>true</final>
</property>
<property>
  <name>fs.default.name</name>
  <value>hdfs://dev-desktop-v1:9000/</value>
</property>
<property>
  <name>fs.trash.interval</name>
  <value>1440</value>
  <final>true</final>
</property>
<property>
  <name>hadoop.tmp.dir</name>
  <value>/tmp/hadoop</value>
  <final>true</final>
</property>
<property>
  <name>io.file.buffer.size</name>
  <value>65536</value>
</property>
<property>
  <name>mapred.child.java.opts</name>
  <value>-Xmx648m</value>
</property>
<property>
  <name>mapred.child.ulimit</name>
  <value>1327104</value>
  <final>true</final>
</property>
<property>
  <name>mapred.job.tracker</name>
  <value>dev-desktop-v1:9001</value>
</property>
<property>
  <name>mapred.job.tracker.handler.count</name>
  <value>5</value>
  <final>true</final>
</property>
<property>
  <name>mapred.local.dir</name>
  <value>/tmp/hadoop/mapred/local</value>
  <final>true</final>
</property>
<property>
  <name>mapred.map.tasks.speculative.execution</name>
  <value>True</value>
</property>
<property>
  <name>mapred.reduce.parallel.copies</name>
  <value>5</value>
</property>
<property>
  <name>mapred.reduce.tasks</name>
  <value>1</value>
</property>
<property>
  <name>mapred.reduce.tasks.speculative.execution</name>
  <value>False</value>
</property>
<property>
  <name>mapred.submit.replication</name>
  <value>10</value>
</property>
<property>
  <name>mapred.system.dir</name>
  <value>/hadoop/system/mapred</value>
</property>
<property>
  <name>mapred.tasktracker.map.tasks.maximum</name>
  <value>2</value>
  <final>true</final>
</property>
<property>
  <name>mapred.tasktracker.reduce.tasks.maximum</name>
  <value>1</value>
  <final>true</final>
</property>
<property>
  <name>tasktracker.http.threads</name>
  <value>6</value>
  <final>true</final>
</property>

<property>
  <name>mapred.output.compression.type</name>
  <value>BLOCK</value>
  <description>If the job outputs are to compressed as SequenceFiles, how should
               they be compressed? Should be one of NONE, RECORD or BLOCK.
               Cloudera Hadoop switches this default to BLOCK for better
               performance.
  </description>
</property>
<property>
  <description>If users connect through a SOCKS proxy, we don't want their
   SocketFactory settings interfering with the socket factory associated
   with the actual daemons.</description>
  <name>hadoop.rpc.socket.factory.class.default</name>
  <value>org.apache.hadoop.net.StandardSocketFactory</value>
  <final>true</final>
</property>
<property>
  <name>hadoop.rpc.socket.factory.class.ClientProtocol</name>
  <value></value>
  <final>true</final>
</property>
<property>
  <name>hadoop.rpc.socket.factory.class.JobSubmissionProtocol</name>
  <value></value>
  <final>true</final>
</property>

<property>
  <name>mapred.map.output.compression.codec</name>
  <value>org.apache.hadoop.io.compress.LzoCodec</value>
  <description>If the map outputs are compressed, how should they be
               compressed? Cloudera Hadoop has detected native LZO compression
               libraries on your system and has selected these for better
               perofrmance.
  </description>
</property>
<property>
  <name>mapred.compress.map.output</name>
  <value>true</value>
</property>
<property>
  <name>mapred.output.compression.codec</name>
  <value>org.apache.hadoop.io.compress.LzoCodec</value>
</property>

<property>
  <name>io.compression.codecs</name>
  <value>org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.LzoCodec</value>
  <description>A list of the compression codec classes that can be used
               for compression/decompression.</description>
</property>
</configuration>
