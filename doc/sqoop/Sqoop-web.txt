
include::../../repos/hadoop/src/contrib/sqoop/doc/intro.txt[]

Getting Sqoop
-------------

Sqoop is an open source program contributed to the Apache
Hadoop project, and included in
link:http://www.cloudera.com/hadoop[Cloudera's Distribution for Hadoop].
The most recent release already contains Sqoop. If you've
been using our RPM packages, running `yum update hadoop-0.20`
should bring you up to date. Debian users can upgrade to the
newest release of Cloudera's Distribution for Hadoop by
running `apt-get update && apt-get install hadoop-0.20`.

.Sqoop and Hadoop 0.18.3
NOTE: A version of Sqoop compatible with Hadoop 0.18.3 was
included with Cloudera's Distribution for Hadoop 0.18.3. All
new Sqoop development, however, will focus on the 0.20 branch
of Hadoop. This document describes some features only present
on the 0.20 branch of Sqoop.


The Sqoop Command Line
----------------------

The main way to execute Sqoop is via a program installed 
as `/usr/bin/sqoop`. You pass this program options describing the
import job you want to perform. If you need a hint, running
`sqoop --help` will print out a list of all the command line
options available. The +sqoop(1)+ manual page will also describe
Sqoop's available arguments in greater detail (type `man sqoop` to
read it.) The following subsections will describe the most
common modes of operation.

Connecting to a Database Server
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sqoop is designed to import tables from a database into HDFS. As such,
it requires a _connect string_ that describes how to connect to the
database. The _connect string_ looks like a URL, and is communicated to
Sqoop with the +--connect+ argument. This describes the server and
database to connect to; it may also specify the port. e.g.: 

----
$ sqoop --connect jdbc:mysql://database.example.com/employees
----

This string will connect to a MySQL database named +employees+ on the
host +database.example.com+. It's important that you *do not* use the URL
+localhost+ if you intend to use Sqoop with a distributed Hadoop
cluster. The connect string you supply will be used on TaskTracker nodes
throughout your MapReduce cluster; if they're told to connect to the
literal name +localhost+, they'll each reach a different
database (or more likely, no database at all)! Instead, you should use
the full hostname or IP address of the database host that can be seen
by all your remote nodes.

You may need to authenticate against the database before you can
access it. The +--username+ and +--password+ or +-P+ parameters can
be used to supply a username and a password to the database. e.g.:

----
$ sqoop --connect jdbc:mysql://database.example.com/employees \
    --username aaron --password 12345
----

.Password security
WARNING: The +--password+ parameter is insecure, as other users may
be able to read your password from the command-line arguments via
the output of programs such as `ps`. The *+-P+* argument will read
a password from a console prompt, and is the preferred method of
entering credentials. Credentials may still be transferred between
nodes of the MapReduce cluster using insecure means.

Sqoop automatically supports several databases, including MySQL. Connect strings beginning
with +jdbc:mysql://+ are handled automatically by
JDBC drivers that are bundled with Sqoop. (A full list of databases with
built-in support is provided in the "Supported Databases" section, below.)

You can use Sqoop with any other
JDBC-compliant database as well. First, download the appropriate JDBC
driver for the database you want to import from, and install the .jar
file in the +/usr/hadoop/lib+ directory on all machines in your Hadoop
cluster, or some other directory which is in the classpath
on all nodes. Each driver jar also has a specific driver class which defines
the entry-point to the driver. For example, MySQL's Connector/J library has
a driver class of +com.mysql.jdbc.Driver+. Refer to your database
vendor-specific documentation to determine the main driver class.
This class must be provided as an argument to Sqoop with +--driver+.

For example, to connect to a postgres database, first download the driver from
link:http://jdbc.postgresql.org[http://jdbc.postgresql.org] and
install it in your Hadoop lib path.
Then run Sqoop with something like:

----
$ sqoop --connect jdbc:postgresql://postgres-server.example.com/employees \
    --driver org.postgresql.Driver
----

NOTE: Sqoop uses the JDBC specification to connect to databases; this
should provide a versatile client that interoperates with many different
databases. We have thoroughly tested this tool with a few databases, such as MySQL.
A complete list is provided in the "Supported Databases" section below. If
you try this tool with another database, please share your success (or
problems!) with us on our
link:http://getsatisfaction.com/cloudera/products/cloudera_sqoop[Sqoop
support and feedback] page.


include::../../repos/hadoop/src/contrib/sqoop/doc/listing-dbs.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/listing-tables.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/full-db-import.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/table-import.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/controlling-output-format.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/controlling-input-format.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/classnames.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/misc-args.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/direct.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/hive.txt[]

include::../../repos/hadoop/src/contrib/sqoop/doc/supported-dbs.txt[]

Cloudera's Distribution for Hadoop includes JDBC drivers for
HSQLDB and MySQL.

Troubleshooting and Getting Help
--------------------------------

include::troubleshooting.txt[]

