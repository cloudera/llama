<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<configuration>

  <!-- LlamaAM Thrift server configuration -->
  <property>
    <name>llama.am.server.thrift.address</name>
    <value>0.0.0.0:15000</value>
    <description>The address the LlamaAM server listen at.
      If 0.0.0.0 is specified as IP, the server will listen in all available
      network addresses. IMPORTANT: if security is enabled do not use 0.0.0.0,
      instead, use the exact same hostname used in the kerberos service 
      principal of the LlamaAM server (i.e. llama/HOSTNAME).
      If the port is not specified, the default port is 15000. 
      If the specified port is 0, an ephemeral port will be used, the port in
      use will be printed in the logs at startup.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.server.min.threads</name>
    <value>10</value>
    <description>
      Minimum number of threads used by the LlamaAM server uses for serving
      client requests.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.server.max.threads</name>
    <value>50</value>
    <description>
      Maximum number of threads used by the LlamaAM server uses for serving
      client requests.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.transport.timeout.ms</name>
    <value>1000</value>
    <description>
      Socket time, in milliseconds, used LlamaAM server for all its server and 
      client Thrift connections.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.client.notifier.queue.threshold</name>
    <value>10000</value>
    <description>
      Threshold of the outstanding client notification queue size to start 
      producing warnings. The queue will continue to queue notifications 
      requests when above the threshold.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.client.notifier.threads</name>
    <value>10</value>
    <description>
      Number of threads used to do client notifications.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.client.notifier.max.retries</name>
    <value>5</value>
    <description>
      Maximum number of retries for a client notification.
      After the maximum number of client notification retries has been reached
      without success the client is considered lost and all its reservations
      are released.
      A successful client notification resets the retries count.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.client.notifier.retry.interval.ms</name>
    <value>5000</value>
    <description>
      Client notification retry interval, in milliseconds.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.node.name.mapping.class</name>
    <value>com.cloudera.llama.am.HostnameOnlyNodeMapper</value>
    <description>
      The NodeMapper implementation LlamaAM server uses to convert requested
      locations into Yarn Nodes.
      The default (and only implementation for production) drops the port
      number if present (Impala uses DataNode addresses to request a location,
      these addresses may contain the DataNode port number. The DataNode port
      number is meaningless and unknown to Yarn).
    </description>
  </property>

  <!-- LlamaAM Thrift server HTTP configuration -->
  <property>
    <name>llama.am.server.thrift.http.address</name>
    <value>0.0.0.0:15001</value>
    <description>The address the LlamaAM server exposes its HTTP server for
      JMX and the Web UI.
      If 0.0.0.0 is specified as IP, the server will listen in all available
      network addresses.
      If the port is not specified, the default port is 15001.
      The HTTP JSON JMX servlet is exposed over HTTP at '/jmx', i.e.:
        http://localhost:15001/jmx
      If the specified port is 0, an ephemeral port will be used, the port in
      use will be printed in the logs at startup.
    </description>
  </property>

  <!-- LlamaAM Thrift server Security configuration -->
  <property>
    <name>llama.am.server.thrift.security</name>
    <value>false</value>
    <description>
      Indicates if security is enabled or not. If enabled, LlamaAM server uses
      Kerberos Thrift SASL for all server and client Thrift connections.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.kerberos.keytab.file</name>
    <value>llama.keytab</value>
    <description>
      The location of the LlamaAM server keytab. If the path is relative,
      the keytab file is looked up in LlamaAM configuration directory.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.kerberos.server.principal.name</name>
    <value>llama/_HOST</value>
    <description>
      LlamaAM Kerberos principal name. 
      The _HOST string is replaced with the canonical hostname.
      It is recommended to explicitly set the hostname to avoid issues do to
      OS network configuration changes.
    </description>
  </property>
  <property>
    <name>llama.am.server.thrift.kerberos.notification.principal.name</name>
    <value>impala</value>
    <description>
      Principal short name, without the service hostname, used for client
      notifications. The hostname provided in the client address at registration
      by the client will be used as service hostname. IMPORTANT: they client
      hostname address provided at registration must match the service name
      in the client's Kerberos principal.
    </description>
  </property>

  <!-- LlamaAM configuration -->
  <property>
    <name>llama.am.rm.connector.class</name>
    <value>com.cloudera.llama.am.yarn.YarnRMLlamaAMConnector</value>
    <description>
      Backing LlamaAM implementation to use.
      Available for functional testing:
      MockRMLlamaAMConnector
    </description>
  </property>
  <property>
    <name>llama.am.initial.queues</name>
    <value>queue1,queue2</value>
    <description>
      Queues LlamaAM should connect at start up.
    </description>
  </property>

  <!-- Gang anti-deadlock configuration -->

  <property>
    <name>llama.am.gang.anti.deadlock.enabled</name>
    <value>true</value>
    <description>
      Enables Llama AM gang scheduling anti deadlock detection.
    </description>
  </property>

  <property>
    <name>llama.am.gang.anti.deadlock.no.allocation.limit.ms</name>
    <value>30000</value>
    <description>
      Interval of time without any new allocation that will trigger the Llama AM
      anti-deadlock logic.
    </description>
  </property>

  <property>
    <name>llama.am.gang.anti.deadlock.backoff.percent</name>
    <value>30</value>
    <description>
      Percentage of resources that will be backed off by the Llama AM
      anti-deadlock logic.
      Random reservations will be backed off until the percentage of backed off
      resources reaches this percentage.
    </description>
  </property>

  <property>
    <name>llama.am.gang.anti.deadlock.backoff.min.delay.ms</name>
    <value>10000</value>
    <description>
      Minimum amount of time the backed off reservations will be in 'backed off'
      state.
      The actual amount time is a random value between the minimum and the
      maximum.
    </description>
  </property>

  <property>
    <name>llama.am.gang.anti.deadlock.backoff.max.delay.ms</name>
    <value>30000</value>
    <description>
      Maximum amount of time the backed off reservations will be in 'backed off'
      state.
      The actual amount time is a random value between the minimum and the
      maximum.
    </description>
  </property>

  <!-- MockLlamaAM configuration -->
  <property>
    <name>llama.am.mock.nodes</name>
    <value>node1,node2</value>
    <description>
      List of nodes to offer.
    </description>
  </property>
  <property>
    <name>llama.am.mock.queues</name>
    <value>queue1,queue2</value>
    <description>
      List of queues to offer.
    </description>
  </property>
  <property>
    <name>llama.am.mock.events.min.wait.ms</name>
    <value>1000</value>
    <description>
      Minimum wait time, in milliseconds, for events to be delivered after
      reservation. Actual wait time is a random value.
    </description>
  </property>
  <property>
    <name>llama.am.mock.events.max.wait.ms</name>
    <value>10000</value>
    <description>
      Maximum wait time, in milliseconds, for events to be delivered after
      reservation. Actual wait time is a random value.
    </description>
  </property>

  <!-- YarnLlamaAM configuration -->
  <property>
    <name>llama.am.hadoop.user.name</name>
    <value>llama</value>
    <description>
      User name use by Llama when interacting with Yarn.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.priority</name>
    <value>0</value>
    <description>
      Application priority when creating application in Yarn Resource Manager.
      NOTE: currently YARN does not use the application priority for 
      scheduling decisions.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.app.monitor.timeout.ms</name>
    <value>30000</value>
    <description>
      Timeout, in milliseconds, for waiting the Application Master to start
      or to stop.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.app.monitor.polling.ms</name>
    <value>200</value>
    <description>
      Polling interval, in milliseconds, to determine if the Application Master
      has started or stopped.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.app.heartbeat.interval.ms</name>
    <value>200</value>
    <description>
      LlamaAM Application Master heartbeat interval, in milliseconds. On each
      heartbeat the Application Master submits new reservations to Yarn Resource
      Manager and gets updates from it.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.container.handler.queue.threshold</name>
    <value>10000</value>
    <description>
      Threshold of the outstanding container requests queue size to Yarn Node 
      Managers to start producing warnings. The queue will continue to queue 
      container requests when above the threshold.
    </description>
  </property>
  <property>
    <name>llama.am.yarn.container.handler.threads</name>
    <value>10</value>
    <description>
      Number of threads used to do container requests to Yarn Node Managers.
    </description>
  </property>

</configuration>
